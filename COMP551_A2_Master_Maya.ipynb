{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /opt/homebrew/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mayaarvanitis/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.11/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from nltk) (4.66.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (3.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mayaarvanitis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mayaarvanitis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mayaarvanitis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assignment 2 COMP 551\n",
    "#Imports\n",
    "#%%capture\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn \n",
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Word\n",
       "0  the\n",
       "1  and\n",
       "2    a\n",
       "3   of\n",
       "4   to"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the directory to the dataset\n",
    "dir = 'aclImdb'\n",
    "\n",
    "# read IMDb vocabulary\n",
    "vocab = pd.read_csv(\"aclImdb/imdb.vocab\", header=None)\n",
    "\n",
    "# rename the only column\n",
    "vocab.columns = [\"Word\"]\n",
    "\n",
    "# first 5 entries\n",
    "vocab.head()\n",
    "# len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working with the already processed Bag of Words files\n",
    "X_train, y_train = load_svmlight_file(\"aclImdb/train/labeledBow.feat\")\n",
    "X_test, y_test = load_svmlight_file(\"aclImdb/test/labeledBow.feat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = np.zeros(vocab.shape[0])\n",
    "# loop through both X_train and X_test\n",
    "for dataset in (X_train, X_test):\n",
    "  # loop through every input in either X_train or X_test\n",
    "  for input in dataset:\n",
    "    used_words = np.bincount(input.indices, minlength=89527)\n",
    "    word_df += used_words\n",
    "\n",
    "word_df /= 50000 # to get frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9118e-01, 9.6594e-01, 9.6648e-01, ..., 2.0000e-05, 2.0000e-05,\n",
       "       2.0000e-05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89527\n"
     ]
    }
   ],
   "source": [
    "print(len(word_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed words: \n",
      "                    Word\n",
      "0                    the\n",
      "1                    and\n",
      "2                      a\n",
      "3                     of\n",
      "4                     to\n",
      "...                  ...\n",
      "89522          copywrite\n",
      "89523             artbox\n",
      "89524          kinky-sex\n",
      "89525           urrrghhh\n",
      "89526  investigator-like\n",
      "\n",
      "[87791 rows x 1 columns]\n",
      "Remaining words: \n",
      "            Word\n",
      "21            he\n",
      "23           his\n",
      "27             !\n",
      "30            by\n",
      "31            an\n",
      "...          ...\n",
      "2012  references\n",
      "2014       stock\n",
      "2039       board\n",
      "2047      leader\n",
      "2051       plots\n",
      "\n",
      "[1736 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# find rare words and stop words in the vocabulary\n",
    "filtered_vocab = np.logical_or(word_df < 0.01, word_df > 0.5) # creates a Boolean mask whether or not the word in the df meets the criteria\n",
    "\n",
    "# filter out the above words\n",
    "removed_feature_words = vocab[filtered_vocab] # apply the mask to the vocabulary\n",
    "vocab = vocab[np.logical_not(filtered_vocab)]\n",
    "\n",
    "# print removed words\n",
    "print(\"Removed words: \")\n",
    "print(removed_feature_words)\n",
    "\n",
    "# print remaining words\n",
    "print(\"Remaining words: \")\n",
    "print(vocab)\n",
    "\n",
    "# re-index the vacabulary after the filtering\n",
    "vocab.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (25000, 89527)\n",
      "Length of filtered_vocab: 89527\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Length of filtered_vocab:\", len(filtered_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import diags \n",
    "\n",
    "X_train = X_train@diags(np.logical_not(filtered_vocab).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.nonzero(X_train) # A tuple of two elements: First has indices of non-all zero rows, second non-all zero columns\n",
    "columns_to_keep_non_unique = indices[1] # Extract a list of indices of the non-all zero columns\n",
    "columns_to_keep_unique = sorted(set(columns_to_keep_non_unique)) # Make the list unique\n",
    "X_train = X_train[:,columns_to_keep_unique] # Make a sparse matrix of the columns to keep (Not all zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test@diags(np.logical_not(filtered_vocab[:-4]).astype(int))\n",
    "indices = np.nonzero(X_test) # A tuple of two elements: First has indices of non-all zero rows, second non-all zero columns\n",
    "columns_to_keep_non_unique = indices[1] # Extract a list of indices of the non-all zero columns\n",
    "columns_to_keep_unique = sorted(set(columns_to_keep_non_unique)) # Make the list unique\n",
    "X_test = X_test[:,columns_to_keep_unique] # Make a sparse matrix of the columns to keep (Not all zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Merge the y's into a single vertical output vector\n",
    "all_y = np.concatenate((y_train, y_test)).reshape(-1, 1)\n",
    "\n",
    "# Standardize the output vector\n",
    "standardized_y = StandardScaler().fit_transform(all_y)\n",
    "\n",
    "# Visualize the result's shape as a sanity check\n",
    "print(standardized_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1736)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import vstack \n",
    "\n",
    "# Merge the X's into a single matrix\n",
    "all_X = vstack((X_train, X_test)).toarray() # We convert to a numpy array because the number of features is now small enough\n",
    "\n",
    "# Standardize the output vector\n",
    "standardized_X = StandardScaler().fit_transform(all_X)\n",
    "\n",
    "# Visualize the result's shape as a sanity check\n",
    "print(standardized_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000, 1736)\n",
      "y_train shape: (25000, 1)\n",
      "X_test shape: (25000, 1736)\n",
      "y_test shape: (25000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the y values\n",
    "standardized_y_train = StandardScaler().fit_transform(y_train.reshape(-1, 1))\n",
    "standardized_y_test = StandardScaler().fit_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Standardize the X values\n",
    "standardized_X_train = StandardScaler().fit_transform(X_train.toarray())\n",
    "standardized_X_test = StandardScaler().fit_transform(X_test.toarray())\n",
    "\n",
    "# Check the dimensions of the resulting arrays\n",
    "print(\"X_train shape:\", standardized_X_train.shape)\n",
    "print(\"y_train shape:\", standardized_y_train.shape)\n",
    "print(\"X_test shape:\", standardized_X_test.shape)\n",
    "print(\"y_test shape:\", standardized_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # initialize weights and bias\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # reshape y to ensure compatibility\n",
    "        y = y.reshape(-1)  # Convert y to a 1D array\n",
    "\n",
    "        # gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # calculate gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))  # shape: (n_features,)\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)         # shape: Scalar\n",
    "\n",
    "            # update weights and bias\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(standardized_X_train, standardized_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/ygq6s9sx7vddpn9fgcmn87n40000gn/T/ipykernel_98028/1166546628.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  most_positive_words[\"Regression coefficient\"] = (-np.sort(-coefficients)[:100]).tolist()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Regression coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>great</td>\n",
       "      <td>0.055175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>best</td>\n",
       "      <td>0.046501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.043752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.036544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>loved</td>\n",
       "      <td>0.035286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>unique</td>\n",
       "      <td>0.011346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>thanks</td>\n",
       "      <td>0.011334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>captured</td>\n",
       "      <td>0.011325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>stunning</td>\n",
       "      <td>0.011261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>day</td>\n",
       "      <td>0.011115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Regression coefficient\n",
       "56        great                0.055175\n",
       "88         best                0.046501\n",
       "282   excellent                0.043752\n",
       "342   wonderful                0.036544\n",
       "410       loved                0.035286\n",
       "...         ...                     ...\n",
       "895      unique                0.011346\n",
       "1146     thanks                0.011334\n",
       "1722   captured                0.011325\n",
       "1291   stunning                0.011261\n",
       "223         day                0.011115\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the 100 words with the most postive coefficients\n",
    "most_positive_word_indices = np.argsort(-coefficients) # We use - so that the most positive become the most negative and appear first\n",
    "most_positive_words = vocab.iloc[most_positive_word_indices[:100]]\n",
    "\n",
    "# append their corresponding coefficients to the dataframe as a column\n",
    "most_positive_words[\"Regression coefficient\"] = (-np.sort(-coefficients)[:100]).tolist()\n",
    "most_positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/ygq6s9sx7vddpn9fgcmn87n40000gn/T/ipykernel_98028/3612209038.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  most_negative_words[\"Regression coefficient\"] = np.sort(coefficients)[:100].tolist()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Regression coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.074413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.059284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.057946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.045368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>avoid</td>\n",
       "      <td>-0.037273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>obvious</td>\n",
       "      <td>-0.011702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>stay</td>\n",
       "      <td>-0.011646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>half</td>\n",
       "      <td>-0.011644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>d</td>\n",
       "      <td>-0.011620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>looks</td>\n",
       "      <td>-0.011590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  Regression coefficient\n",
       "213     worst               -0.074413\n",
       "50        bad               -0.059284\n",
       "400     waste               -0.057946\n",
       "341     awful               -0.045368\n",
       "733     avoid               -0.037273\n",
       "...       ...                     ...\n",
       "532   obvious               -0.011702\n",
       "730      stay               -0.011646\n",
       "328      half               -0.011644\n",
       "1293        d               -0.011620\n",
       "233     looks               -0.011590\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 words with the most negative coefficients\n",
    "most_negative_word_indices = np.argsort(coefficients)\n",
    "most_negative_words = vocab.iloc[most_negative_word_indices[:100]]\n",
    "\n",
    "# append their corresponding coefficients to the dataframe as a column\n",
    "most_negative_words[\"Regression coefficient\"] = np.sort(coefficients)[:100].tolist()\n",
    "\n",
    "# print the results\n",
    "most_negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_y_pred = X.dot(self.weights) + self.bias\n",
    "            logistic_y_pred = self.sigmoid(linear_y_pred)\n",
    "\n",
    "            dw = (1 / n_samples) * X.T.dot(logistic_y_pred - y)\n",
    "            db = (1 / n_samples) * np.sum(logistic_y_pred - y)\n",
    "\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_y_pred = X.dot(self.weights) + self.bias\n",
    "        logistic_y_pred = self.sigmoid(linear_y_pred)\n",
    "        class_pred = np.where(logistic_y_pred > 0.5, 1, 0) \n",
    "        return class_pred\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 100 features based on coefficients\n",
    "top_100_features_indices = np.argsort(coefficients)[-100:][::-1]\n",
    "\n",
    "# create a mask array to select columns corresponding to the top features\n",
    "mask = np.zeros(X_train.shape[1], dtype=bool)\n",
    "mask[top_100_features_indices] = True\n",
    "\n",
    "# apply the mask to select the top features from X_train\n",
    "X_train_top_100 = X_train[:, mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_selected_features = X_test[:, top_100_features_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_binary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train a logistic regression model on the training data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m logistic_regression_model \u001b[38;5;241m=\u001b[39m LogisticRegression(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, n_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m logistic_regression_model\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[43my_train_binary\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_binary' is not defined"
     ]
    }
   ],
   "source": [
    "# train a logistic regression model on the training data\n",
    "logistic_regression_model = LogisticRegression(lr=0.001, n_iters=1000)\n",
    "logistic_regression_model.fit(X_train, y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "y_test_binary = np.where(y_test > threshold, 1, 0)\n",
    "y_train_binary = np.where(y_train > threshold, 1, 0)\n",
    "y_test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(y_pred, y_test):\n",
    "    return np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "acc = accuracy1(y_pred, y_test_binary)\n",
    "print(\"Logistic Regression Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model\n",
    "dt_classifier.fit(X_train, y_train_binary)\n",
    "\n",
    "# predict\n",
    "dt_y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "dt_acc = accuracy_score(y_test_binary, dt_y_pred)\n",
    "print(\"Decision Tree Accuracy:\", dt_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# top 10 words with the most postive coefficients\n",
    "top_10_indices = np.argsort(-coefficients) # We use - so that the most positive become the most negative and appear first\n",
    "top_10 = vocab.iloc[top_10_indices[:10]]\n",
    "\n",
    "# append their corresponding coefficients to the dataframe as a column\n",
    "top_10[\"Regression coefficient\"] = (-np.sort(-coefficients)[:10]).tolist()\n",
    "\n",
    "# bottom 100 words with the most negative coefficients\n",
    "bottom_10_indices = np.argsort(coefficients)\n",
    "bottom_10 = vocab.iloc[most_negative_word_indices[:10]]\n",
    "\n",
    "# append their corresponding coefficients to the dataframe as a column\n",
    "bottom_10[\"Regression coefficient\"] = np.sort(coefficients)[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_feature_names = top_10[\"Word\"].tolist() + bottom_10[\"Word\"].tolist()\n",
    "top_coefficients = (-np.sort(-coefficients)[:10]).tolist() + np.sort(coefficients)[:10].tolist()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['green' if c > 0 else 'red' for c in top_coefficients]\n",
    "plt.barh(top_feature_names, top_coefficients, color=colors)\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Word')\n",
    "plt.title('Top 20 Features from Simple Linear Regression')\n",
    "plt.grid(axis='x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area for logistic regression\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_binary, y_pred)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "# Compute ROC curve and ROC area for Decision Tree\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test_binary, dt_y_pred)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label='Logistic Regression (AUC = %0.2f)' % roc_auc_lr)\n",
    "plt.plot(fpr_dt, tpr_dt, color='red', lw=2, label='Decision Tree (AUC = %0.2f)' % roc_auc_dt)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "all_y_binary = np.where(all_y > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X, all_y_binary, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the percentages of training data\n",
    "training_data_percentages = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "# Initialize lists to store AUROC values\n",
    "auroc_lr = []\n",
    "auroc_dt = []\n",
    "\n",
    "# Loop over different percentages of training data\n",
    "for percentage in training_data_percentages:\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_X, all_y_binary, test_size=1 - percentage, random_state=42)\n",
    "    \n",
    "    # Train logistic regression model\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Train Decision Tree model\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for logistic regression\n",
    "    y_pred_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Predict probabilities for Decision Tree\n",
    "    y_pred_dt = dt_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate AUROC for logistic regression\n",
    "    auroc_lr.append(roc_auc_score(y_test, y_pred_lr))\n",
    "    \n",
    "    # Calculate AUROC for Decision Tree\n",
    "    auroc_dt.append(roc_auc_score(y_test, y_pred_dt))\n",
    "\n",
    "# Plot the AUROC values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(np.arange(len(training_data_percentages)) - 0.15, auroc_lr, width=0.3, label='Logistic Regression')\n",
    "plt.bar(np.arange(len(training_data_percentages)) + 0.15, auroc_dt, width=0.3, label='Decision Tree')\n",
    "plt.xticks(np.arange(len(training_data_percentages)), [f\"{int(p * 100)}%\" for p in training_data_percentages])\n",
    "plt.xlabel('Percentage of Training Data')\n",
    "plt.ylabel('AUROC')\n",
    "plt.title('AUROC of Models with Different Training Data Percentages')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the percentage of training data (20%)\n",
    "percentage = 0.4\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_X, all_y_binary, test_size=1 - percentage, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Decision Tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for logistic regression\n",
    "y_pred_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predict probabilities for Decision Tree\n",
    "y_pred_dt = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate AUROC for logistic regression\n",
    "auroc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "\n",
    "# Calculate AUROC for Decision Tree\n",
    "auroc_dt = roc_auc_score(y_test, y_pred_dt)\n",
    "\n",
    "# Plot the AUROC values for 20% training data\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(['Logistic Regression', 'Decision Tree'], [auroc_lr, auroc_dt])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('AUROC')\n",
    "plt.title('AUROC for 20% Training Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 newsgroups Dataset\n",
    "\n",
    "The five chosen categories of newsgroups are the following:\n",
    "    1. comp.graphics\n",
    "    2. soc.religion.christian\n",
    "    3. rec.sport.hockey\n",
    "    4. sci.space\n",
    "    5. talk.politics.guns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset and downloads \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#fetching the dataset (all data)\n",
    "all_newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "all_newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "print(\"Length of training data (before choosing 5 categories): \" + str(len(all_newsgroups_train.data)))\n",
    "print (\"Length of test data (before choosing 5 categories): \" + str(len(all_newsgroups_test.data)))\n",
    "\n",
    "#Choosing 5 categories\n",
    "chosen_categories = ['comp.graphics', 'soc.religion.christian', 'rec.sport.hockey', 'sci.space', 'talk.politics.guns']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=chosen_categories, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=chosen_categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print(\"Length of training data (after choosing 5 categories): \" + str(len(newsgroups_train.data)))\n",
    "print (\"Length of test data (after choosing 5 categories): \" + str(len(newsgroups_test.data)) + '\\n')\n",
    "\n",
    "#for data visualization purposes, printing the head of the dataset\n",
    "newsgroups_train_df = pd.DataFrame({'text': newsgroups_train.data, 'category': newsgroups_train.target})\n",
    "print(\"Train Data Frame\")\n",
    "display(newsgroups_train_df.head())\n",
    "\n",
    "newsgroups_test_df = pd.DataFrame({'text': newsgroups_test.data, 'category': newsgroups_test.target})\n",
    "print(\"Test Data Frame\")\n",
    "display(newsgroups_test_df.head())\n",
    "\n",
    "#note the corresponding number values for each category\n",
    "for index, category in enumerate(newsgroups_train.target_names):\n",
    "    print(f'Category Number: {index} -> Category Name: {category}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected a subset of the data, we will visualize its distribution to ensure the categories of news are relatively well balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the distribution of categories selected through a bar graph\n",
    "\n",
    "#count the number of documents in each category\n",
    "category_counts = newsgroups_train_df['category'].value_counts()\n",
    "\n",
    "#convert the categories numbers to their names\n",
    "category_names = [newsgroups_train.target_names[i] for i in category_counts.index]\n",
    "\n",
    "#calculate the category percentages\n",
    "category_percentages = category_counts / category_counts.sum() * 100\n",
    "\n",
    "#plot the distribution \n",
    "plt.figure(figsize=(5,2.5))\n",
    "plt.bar(category_names, category_counts)\n",
    "plt.title('Distribution of Categories for Training Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plot a pie chart\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.pie(category_percentages, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Percentage of Documents in Each Category')\n",
    "plt.show()\n",
    "\n",
    "#same steps for the test data\n",
    "category_counts = newsgroups_test_df['category'].value_counts()\n",
    "category_names = [newsgroups_test.target_names[i] for i in category_counts.index]\n",
    "category_percentages = category_counts / category_counts.sum() * 100\n",
    "\n",
    "plt.figure(figsize=(5, 2.5))\n",
    "plt.bar(category_names, category_counts)\n",
    "plt.title('Distribution of Categories for Test Data')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plot a pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(category_percentages, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Percentage of Documents in Each Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have seen our data in both training and testing is well balanced. So we can continue with further preprocessing steps. \n",
    "\n",
    "Note the folowing numbers and their associated category names:\n",
    "\n",
    "Category Number: 0 -> Category Name: comp.graphics\n",
    "Category Number: 1 -> Category Name: rec.sport.hockey\n",
    "Category Number: 2 -> Category Name: sci.space\n",
    "Category Number: 3 -> Category Name: soc.religion.christian\n",
    "Category Number: 4 -> Category Name: talk.politics.guns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Several preprocessing steps are required before training our model. We will lowercase the entries, remove punctuation, special characters and numbers as well as double spaces. We will then remove stopwords and filter out any empty entires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing steps ============\n",
    "#TRAINING DATA =============================\n",
    "#lowercase the entries\n",
    "newsgroups_train.data = [text.lower() for text in newsgroups_train.data]\n",
    "#regex to remove tags, etc.\n",
    "newsgroups_train.data = [re.sub(r'(<br\\s*/>\\s*)+|(/)|(\\n)|(-)', '', text) for text in newsgroups_train.data]\n",
    "#removing punctuation\n",
    "newsgroups_train.data = [text.translate(str.maketrans('', '', string.punctuation)) for text in newsgroups_train.data]\n",
    "#removing numbers and any other special characters\n",
    "newsgroups_train.data = [re.sub(r'[^a-z\\s]', '', text) for text in newsgroups_train.data]\n",
    "#remove any double spaces\n",
    "newsgroups_train.data = [re.sub(r'\\s+', ' ', text) for text in newsgroups_train.data]\n",
    "\n",
    "# Filter out empty entries and update both data and target\n",
    "filtered_data = []\n",
    "filtered_target = []\n",
    "for text, target in zip(newsgroups_train.data, newsgroups_train.target):\n",
    "    if text.strip():\n",
    "        filtered_data.append(text)\n",
    "        filtered_target.append(target)\n",
    "\n",
    "newsgroups_train.data = filtered_data\n",
    "newsgroups_train.target = np.array(filtered_target)\n",
    "\n",
    "#removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    entry_nostopwords = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(entry_nostopwords)\n",
    "\n",
    "#call remove_stopwords function\n",
    "newsgroups_train.data = [remove_stopwords(entry) for entry in newsgroups_train.data]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "newsgroups_train_df_cleaned = pd.DataFrame({'entry (Data)': newsgroups_train.data, 'target': newsgroups_train.target})\n",
    "display(newsgroups_train_df_cleaned.head())\n",
    "\n",
    "#TEST DATA =============================\n",
    "#lowercase the entries\n",
    "newsgroups_test.data = [text.lower() for text in newsgroups_test.data]\n",
    "#regex to remove tags, etc.\n",
    "newsgroups_test.data = [re.sub(r'(<br\\s*/>\\s*)+|(/)|(\\n)|(-)', '', text) for text in newsgroups_test.data]\n",
    "#removing punctuation\n",
    "newsgroups_test.data = [text.translate(str.maketrans('', '', string.punctuation)) for text in newsgroups_test.data]\n",
    "#removing numbers and any other special characters\n",
    "newsgroups_test.data = [re.sub(r'[^a-z\\s]', '', text) for text in newsgroups_test.data]\n",
    "#remove any double spaces\n",
    "newsgroups_test.data = [re.sub(r'\\s+', ' ', text) for text in newsgroups_test.data]\n",
    "\n",
    "# Filter out empty entries and update both data and target\n",
    "filtered_data = []\n",
    "filtered_target = []\n",
    "for text, target in zip(newsgroups_test.data, newsgroups_test.target):\n",
    "    if text.strip():\n",
    "        filtered_data.append(text)\n",
    "        filtered_target.append(target)\n",
    "        \n",
    "newsgroups_test.data = filtered_data\n",
    "newsgroups_test.target = np.array(filtered_target)\n",
    "\n",
    "#call remove_stopwords \n",
    "newsgroups_test.data = [remove_stopwords(entry) for entry in newsgroups_test.data]\n",
    "\n",
    "y_newsgroups_train = newsgroups_train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text to vectors \n",
    "\n",
    "Using Count Vectorizer we will count the occurences of each token in each document. \n",
    "We used a minimum threshold of 0.01 and a maximum threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(min_df= 0.01, max_df= 0.5)\n",
    "X_train_counts = count_vect.fit_transform(newsgroups_train.data)\n",
    "\n",
    "print(\"Number of unique words in the training data: \" + str(X_train_counts.shape[1]))\n",
    "print(\"The shape of the training data: \" + str(X_train_counts.shape))\n",
    "\n",
    "#perform the same on the test data\n",
    "X_test_counts = count_vect.transform(newsgroups_test.data)\n",
    "\n",
    "print(\"Number of unique words in the test data: \" + str(X_test_counts.shape[1]))\n",
    "print(\"The shape of the test data: \" + str(X_test_counts.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use tf-idf so that we can remove the potential issue of logner documents having a higher average count for words than shorter documents. \n",
    "\n",
    "Tf-idf will downscale the weight of words that occur in many documents are are less informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "X_train_newsgroups = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#perform same on test dataset\n",
    "X_test_newsgroups = tfidf_transformer.fit_transform(X_test_counts)\n",
    "\n",
    "print(\"The shape of the training data after TF-IDF: \" + str(X_train_newsgroups.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Mutual Information (MI) to select features\n",
    "\n",
    "We will use mutual informations cores to determine which features are most important for making predictions. This will tell us the words that are most important in predicting the category of news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Before encoding\n",
    "print(\"The shape of the training target: \" + str(newsgroups_train.target.shape))\n",
    "print(\"Matrix of y_train before one hot encoding: \", newsgroups_train.target)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_onehot = onehot_encoder.fit_transform(newsgroups_train.target.reshape(-1, 1))\n",
    "\n",
    "# After encoding\n",
    "print(\"The shape of the one-hot encoded training target: \" + str(y_train_onehot.shape))\n",
    "print(\"Matrix of y_train after one hot encoding: \\n\", y_train_onehot)\n",
    "\n",
    "#perform the same on the test dataset\n",
    "y_test_onehot = onehot_encoder.fit_transform(newsgroups_test.target.reshape(-1, 1))\n",
    "\n",
    "#update variables\n",
    "y_train_newsgroups = y_train_onehot\n",
    "y_test_newsgroups = y_test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "#number of classes\n",
    "num_classes = len(newsgroups_train.target_names)\n",
    "\n",
    "#number of features\n",
    "num_features = X_train_counts.shape[1]\n",
    "\n",
    "top_features_classes = {}\n",
    "\n",
    "for y_index, class_name in enumerate(newsgroups_train.target_names):\n",
    "    #Debugging purposes\n",
    "    #print(\"Shape of X_train_counts:\", X_train_counts.shape)\n",
    "    #print(\"Shape of y_train_onehot:\", y_train_onehot.shape)\n",
    "    \n",
    "    # Create a binary array for the current class\n",
    "    y_bin = y_train_onehot[:, y_index]\n",
    "\n",
    "    # Calculate MI scores for each feature\n",
    "    mi_scores = [mutual_info_score(X_train_counts[:, i].toarray().flatten(), y_bin) for i in range(num_features)]\n",
    "\n",
    "\n",
    "    # Get the top 100 features\n",
    "    top_indices = np.argsort(mi_scores)[::-1][:100]\n",
    "    \n",
    "    # Get the feature names and scores\n",
    "    top_features = [count_vect.get_feature_names_out()[i] for i in top_indices]\n",
    "    max_mi_scores = [mi_scores[i] for i in top_indices]\n",
    "\n",
    "    # storing the top 100 features\n",
    "    top_features_classes[class_name] = list(zip(top_features, max_mi_scores))\n",
    "\n",
    "# # for vizualization purposes, print the top 100 features for each class\n",
    "# for class_name, features in top_features_classes.items():\n",
    "#     print(f\"Top 100 features for {class_name}:\")\n",
    "#     for feature, score in features:\n",
    "#         print(f\"{feature}: {score}\")\n",
    "#     print()\n",
    "    \n",
    "# convert to a data fram\n",
    "top_features_df = pd.DataFrame(top_features_classes)\n",
    "\n",
    "#displaying the top 10 words for each news category\n",
    "display(top_features_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the union of the top 100 features of each class\n",
    "top_features_union = set().union(*top_features_classes.values())\n",
    "\n",
    "print(\"Number of unique words in the top 100 features for each class: \" + str(len(top_features_union)))\n",
    "\n",
    "# Convert the set to a list\n",
    "top_features_union_list = list(top_features_union)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Multiclass Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multinomial_logistic:\n",
    "    def __init__(self, nFeatures, nClasses):\n",
    "        self.W = np.random.rand(nFeatures, nClasses)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.exp(np.matmul(X, self.W))\n",
    "        return y_pred / y_pred.sum(axis=1).reshape(X.shape[0], 1)\n",
    "\n",
    "    def grad(self, X, y):\n",
    "        return np.matmul(X.transpose(), self.predict(X) - y)\n",
    "\n",
    "    def ce(self, X, y):\n",
    "        return -np.sum(y * np.log(self.predict(X)))\n",
    "\n",
    "    # modify it to add stopping criteria (what can you think of?)\n",
    "    def fit(self, X, y, X_valid=None, y_valid=None, lr=0.005, niter=100):\n",
    "        losses_train = np.zeros(niter)\n",
    "        losses_valid = np.zeros(niter)\n",
    "        for i in range(niter):\n",
    "            self.W = self.W - lr * self.grad(X, y)\n",
    "            loss_train = self.ce(X, y)\n",
    "            losses_train[i] = loss_train\n",
    "            if X_valid is not None and y_valid is not None:\n",
    "                loss_valid = self.ce(X_valid, y_valid)\n",
    "                losses_valid[i] = loss_valid\n",
    "                print(f\"iter {i}: {loss_train:.3f}; {loss_valid:.3f}\")\n",
    "            else:\n",
    "                print(f\"iter {i}: {loss_train:.3f}\")\n",
    "        return losses_train, losses_valid\n",
    "\n",
    "    def check_grad(self, X, y):\n",
    "        N, C = y.shape\n",
    "        D = X.shape[1]\n",
    "\n",
    "        diff = np.zeros((D, C))\n",
    "\n",
    "        W = self.W.copy()\n",
    "\n",
    "        for i in range(D):\n",
    "            for j in range(C):\n",
    "                epsilon = np.zeros((D, C))\n",
    "                epsilon[i, j] = np.random.rand() * 1e-4\n",
    "\n",
    "                self.W = self.W + epsilon\n",
    "                J1 = self.ce(X, y)\n",
    "                self.W = W\n",
    "\n",
    "                self.W = self.W - epsilon\n",
    "                J2 = self.ce(X, y)\n",
    "                self.W = W\n",
    "\n",
    "                numeric_grad = (J1 - J2) / (2 * epsilon[i, j])\n",
    "                derived_grad = self.grad(X, y)[i, j]\n",
    "\n",
    "                diff[i, j] = np.square(derived_grad - numeric_grad).sum() / \\\n",
    "                             np.square(derived_grad + numeric_grad).sum()\n",
    "\n",
    "        # print(diff)\n",
    "        return diff.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables we will use for the 20 news dataset are the following:\n",
    "\n",
    "X_train_newsgroups\n",
    "y_train_newsgroups\n",
    "X_validate_newsgroups\n",
    "y_validate_newsgroups\n",
    "X_test_newsgroups\n",
    "y_test_newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_newsgroups, X_validate_newsgroups, y_train_newsgroups, y_validate_newsgroups = train_test_split(X_train_newsgroups, y_train_newsgroups, test_size = 0.3, random_state = 5, shuffle = True)\n",
    "\n",
    "#print the shapes of all the sets\n",
    "print(\"The shape of the training set: \" + str(X_train_newsgroups.shape))\n",
    "print(\"The shape of the validation set: \" + str(X_validate_newsgroups.shape))\n",
    "print(\"The shape of the test set: \" + str(X_test_counts.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Multi-class prediction classification accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will fit the model and ensure there is no overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure we are dealing with dense arrays \n",
    "X_train_newsgroups = X_train_newsgroups.toarray()\n",
    "X_validate_newsgroups = X_validate_newsgroups.toarray()\n",
    "X_test_newsgroups = X_test_newsgroups.toarray()\n",
    "\n",
    "#create the model\n",
    "model = Multinomial_logistic(nFeatures=X_train_newsgroups.shape[1], nClasses=y_train_onehot.shape[1])\n",
    "\n",
    "#checking the gradient\n",
    "print(\"Gradient for multiclass: \" + str(model.check_grad(X_train_newsgroups, y_train_newsgroups)))\n",
    "\n",
    "#fit the model \n",
    "model.fit(X_train_newsgroups, y_train_newsgroups, X_valid=X_validate_newsgroups, y_valid=y_validate_newsgroups)\n",
    "\n",
    "ce_train, ce_valid = model.fit(X_train_newsgroups, y_train_newsgroups, X_valid=X_validate_newsgroups, y_valid=y_validate_newsgroups)\n",
    "#plot a figure to ensure no overfitting \n",
    "plt.clf()\n",
    "plt.plot(ce_train/X_train_newsgroups.shape[0], label='train')\n",
    "plt.plot(ce_valid/X_validate_newsgroups.shape[0], label='valid')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"CE\")\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "plt.savefig(\"training_ce.png\", bbox_inches=\"tight\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have verfied from the above plot that both training and validation error curves are continuing to decrease for all the iterations. Therefore, we can conlcude there are no errors in overfitting and can evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Classification Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y, y_pred):\n",
    "    accuracy = sum(y_pred.argmax(axis=1) == y.argmax(axis=1))\n",
    "    accuracy = accuracy / y.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = evaluate(model.predict(X_train_newsgroups), y_train_newsgroups)\n",
    "valid_accuracy = evaluate(model.predict(X_validate_newsgroups), y_validate_newsgroups)\n",
    "test_accuracy = evaluate(model.predict(X_test_newsgroups), y_test_newsgroups)\n",
    "\n",
    "print(\"Training accuracy : \" + str(train_accuracy))\n",
    "print(\"Validation accruacy : \" + str(valid_accuracy))\n",
    "print(\"Test accuracy : \" + str(test_accuracy))\n",
    "\n",
    "multiclass_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing multi-label classification with Decision Tree \n",
    "\n",
    "We are going to begin by comparing DT performance and our multi-class model with default hyperparameters and then will perform optimizations for tree depth and classification hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#make a pipeline for decision tree \n",
    "\n",
    "pipeline_dt = Pipeline([\n",
    "    ('clf', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "pipeline_dt.fit(X_train_newsgroups, y_train_newsgroups)\n",
    "\n",
    "y_pred_dt_newsgroups = pipeline_dt.predict(X_test_newsgroups)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test_newsgroups, y_pred_dt_newsgroups)\n",
    "\n",
    "newsgroups_accuracy_df = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Multi-class'],\n",
    "    'Accuracy': [accuracy_dt, multiclass_accuracy]\n",
    "})\n",
    "\n",
    "#display the df\n",
    "display(newsgroups_accuracy_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with max depth optimization\n",
    "\n",
    "Now, we will perform the same comparison but with max depth optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize maximum accuracy and corresponding depth\n",
    "max_accuracy_dt = 0\n",
    "best_depth = 0\n",
    "\n",
    "#increments of max depth \n",
    "for i in [5,10,20,30,40,50,75,100,225,500,1000,2225,3000,5000]:\n",
    "    pipeline_dt = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(max_depth=i)),\n",
    "    ])\n",
    "\n",
    "    pipeline_dt.fit(X_train_newsgroups, y_train_newsgroups)\n",
    "\n",
    "    y_pred_dt_newsgroups = pipeline_dt.predict(X_test_newsgroups)\n",
    "\n",
    "    accuracy_dt = accuracy_score(y_test_newsgroups, y_pred_dt_newsgroups)\n",
    "    \n",
    "    # Update max accuracy and depth if current accuracy is greater\n",
    "    if accuracy_dt > max_accuracy_dt:\n",
    "        max_accuracy_dt = accuracy_dt\n",
    "        best_depth = i\n",
    "\n",
    "print(f\"The maximum accuracy is {max_accuracy_dt} at depth {best_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Running Experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing the accuracy of the multiclass model with DT as a function of the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of training sizes to test\n",
    "training_sizes = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "#initialize the list of accuracies\n",
    "mlr_accuracies = []\n",
    "dt_accuracies = []\n",
    "\n",
    "#loop through the training sizes\n",
    "for size in training_sizes:\n",
    "    #split the data\n",
    "    X_train_newsgroups, X_validate_newsgroups, y_train_newsgroups, y_validate_newsgroups = train_test_split(X_train_newsgroups, y_train_newsgroups, test_size = size, random_state = 5, shuffle = True)\n",
    "    \n",
    "    #create the model\n",
    "    model = Multinomial_logistic(nFeatures=X_train_newsgroups.shape[1], nClasses=y_train_onehot.shape[1])\n",
    "    \n",
    "    #fit the model\n",
    "    model.fit(X_train_newsgroups, y_train_newsgroups, X_valid=X_validate_newsgroups, y_valid=y_validate_newsgroups)\n",
    "    \n",
    "    #get the accuracy\n",
    "    train_accuracy = evaluate(model.predict(X_train_newsgroups), y_train_newsgroups)\n",
    "    valid_accuracy = evaluate(model.predict(X_validate_newsgroups), y_validate_newsgroups)\n",
    "    test_accuracy = evaluate(model.predict(X_test_newsgroups), y_test_newsgroups)\n",
    "    \n",
    "    #append the accuracy to the list\n",
    "    mlr_accuracies.append(test_accuracy)\n",
    "    \n",
    "    #create the pipeline for decision tree\n",
    "    pipeline_dt = Pipeline([\n",
    "        ('clf', DecisionTreeClassifier(max_depth=best_depth)),\n",
    "    ])\n",
    "    \n",
    "    #fit the model\n",
    "    pipeline_dt.fit(X_train_newsgroups, y_train_newsgroups)\n",
    "    \n",
    "    #get the accuracy\n",
    "    y_pred_dt_newsgroups = pipeline_dt.predict(X_test_newsgroups)\n",
    "    accuracy_dt = accuracy_score(y_test_newsgroups, y_pred_dt_newsgroups)\n",
    "    \n",
    "    #append the accuracy to the list\n",
    "    dt_accuracies.append(accuracy_dt)\n",
    "    \n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_sizes, mlr_accuracies, marker='o', label='Multinomial Logistic Regression')\n",
    "plt.plot(training_sizes, dt_accuracies, marker='s', label='Decision Tree')\n",
    "plt.title('Model Accuracy as a Function of Training Set Size')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(training_sizes, [f'{int(size*100)}%' for size in training_sizes])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(len(training_sizes))  \n",
    "width = 0.35  \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, mlr_accuracies, width, label='Multiclass Regression')\n",
    "rects2 = ax.bar(x + width/2, dt_accuracies, width, label='Decision Tree')\n",
    "\n",
    "ax.set_xlabel('Training Data Size')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Classification Accuracies of MLR and DT on Test Data')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'{int(size*100)}%' for size in training_sizes])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap for top 5 most positive features for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of classes \n",
    "class_order = ['comp.graphics', 'rec.sport.hockey', 'sci.space', 'soc.religion.christian', 'talk.politics.guns']\n",
    "\n",
    "rows_list = []\n",
    "\n",
    "# get the top 5 features for each class and append them \n",
    "for class_name in class_order:\n",
    "    features = top_features_classes[class_name][:5]\n",
    "    for feature, score in features:\n",
    "        rows_list.append({'Feature': feature, 'Class': class_name, 'Score': score})\n",
    "\n",
    "features_df = pd.DataFrame(rows_list)\n",
    "\n",
    "features_df['Class'] = pd.Categorical(features_df['Class'], categories=class_order, ordered=True)\n",
    "\n",
    "features_df = features_df.sort_values(by='Class')\n",
    "\n",
    "pivoted_df = features_df.pivot(index='Feature', columns='Class', values='Score')\n",
    "\n",
    "# Fill in any blanks with 0\n",
    "pivoted_df = pivoted_df.fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(pivoted_df, annot=True, cmap='YlGnBu', linewidths=.5)\n",
    "plt.title('Top 5 Features Heatmap by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
