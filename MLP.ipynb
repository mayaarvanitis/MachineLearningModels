{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6734765f-cd55-41ca-9db3-fe12dfb53406",
   "metadata": {},
   "source": [
    "# MLP sign MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f407f93-802b-4b03-983d-c1c0766e3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Imports\n",
    "%pip install keras\n",
    "%pip install tensorflow\n",
    "%pip install kaggle\n",
    "%pip install distutils\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51d9ca3-df2f-48c0-918f-8645431cd17d",
   "metadata": {},
   "source": [
    "## Task 1: Acquire the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1a3f8c-365d-4590-b907-d1f785c90f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('/Users/mayaarvanitis/Desktop/winter2024/COMP551/archive/sign_mnist_train/sign_mnist_train.csv')\n",
    "test_df=pd.read_csv('/Users/mayaarvanitis/Desktop/winter2024/COMP551/archive/sign_mnist_test/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0dfcab-3af3-4a35-be68-5a9299bc5b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27455 entries, 0 to 27454\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 164.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fddac127-55c7-41d2-87b3-0cc464b2c44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "      <td>27455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.318813</td>\n",
       "      <td>145.419377</td>\n",
       "      <td>148.500273</td>\n",
       "      <td>151.247714</td>\n",
       "      <td>153.546531</td>\n",
       "      <td>156.210891</td>\n",
       "      <td>158.411255</td>\n",
       "      <td>160.472154</td>\n",
       "      <td>162.339683</td>\n",
       "      <td>163.954799</td>\n",
       "      <td>...</td>\n",
       "      <td>141.104863</td>\n",
       "      <td>147.495611</td>\n",
       "      <td>153.325806</td>\n",
       "      <td>159.125332</td>\n",
       "      <td>161.969259</td>\n",
       "      <td>162.736696</td>\n",
       "      <td>162.906137</td>\n",
       "      <td>161.966454</td>\n",
       "      <td>161.137898</td>\n",
       "      <td>159.824731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.287552</td>\n",
       "      <td>41.358555</td>\n",
       "      <td>39.942152</td>\n",
       "      <td>39.056286</td>\n",
       "      <td>38.595247</td>\n",
       "      <td>37.111165</td>\n",
       "      <td>36.125579</td>\n",
       "      <td>35.016392</td>\n",
       "      <td>33.661998</td>\n",
       "      <td>32.651607</td>\n",
       "      <td>...</td>\n",
       "      <td>63.751194</td>\n",
       "      <td>65.512894</td>\n",
       "      <td>64.427412</td>\n",
       "      <td>63.708507</td>\n",
       "      <td>63.738316</td>\n",
       "      <td>63.444008</td>\n",
       "      <td>63.509210</td>\n",
       "      <td>63.298721</td>\n",
       "      <td>63.610415</td>\n",
       "      <td>64.396846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>125.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean      12.318813    145.419377    148.500273    151.247714    153.546531   \n",
       "std        7.287552     41.358555     39.942152     39.056286     38.595247   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000    121.000000    126.000000    130.000000    133.000000   \n",
       "50%       13.000000    150.000000    153.000000    156.000000    158.000000   \n",
       "75%       19.000000    174.000000    176.000000    178.000000    179.000000   \n",
       "max       24.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean     156.210891    158.411255    160.472154    162.339683    163.954799   \n",
       "std       37.111165     36.125579     35.016392     33.661998     32.651607   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      137.000000    140.000000    142.000000    144.000000    146.000000   \n",
       "50%      160.000000    162.000000    164.000000    165.000000    166.000000   \n",
       "75%      181.000000    182.000000    183.000000    184.000000    185.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean   ...    141.104863    147.495611    153.325806    159.125332   \n",
       "std    ...     63.751194     65.512894     64.427412     63.708507   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...     92.000000     96.000000    103.000000    112.000000   \n",
       "50%    ...    144.000000    162.000000    172.000000    180.000000   \n",
       "75%    ...    196.000000    202.000000    205.000000    207.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
       "mean     161.969259    162.736696    162.906137    161.966454    161.137898   \n",
       "std       63.738316     63.444008     63.509210     63.298721     63.610415   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      120.000000    125.000000    128.000000    128.000000    128.000000   \n",
       "50%      183.000000    184.000000    184.000000    182.000000    182.000000   \n",
       "75%      208.000000    207.000000    207.000000    206.000000    204.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel784  \n",
       "count  27455.000000  \n",
       "mean     159.824731  \n",
       "std       64.396846  \n",
       "min        0.000000  \n",
       "25%      125.500000  \n",
       "50%      182.000000  \n",
       "75%      204.000000  \n",
       "max      255.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605d6345-ede9-4f89-b6d2-37e91c24e37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>161</td>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>178</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>193</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "5     16     161     168     172     173     178     184     189     193   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "5     196  ...        76        74        68        62        53        55   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "5        48       238       255       255  \n",
       "\n",
       "[6 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7f4ba70-d0b5-4775-9617-7548e392eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range = 0,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  shear_range=0,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "#Normalize Features\n",
    "#Drop the labels\n",
    "X_train = train_df.drop('label', axis=1).values / 255.0\n",
    "X_test = test_df.drop('label', axis=1).values / 255.0\n",
    "y_train = LabelBinarizer().fit_transform(train_df['label'])\n",
    "y_test = LabelBinarizer().fit_transform(test_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dd072-c849-4019-8108-64ba3878b7cd",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef2c78f-f70f-4882-b8ec-cd84d0583595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'label: 13  letter: M')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axe=plt.subplots(2,2)\n",
    "fig.suptitle('Preview of dataset')\n",
    "axe[0,0].imshow(X_train[0].reshape(28,28),cmap='gray')\n",
    "axe[0,0].set_title('label: 3  letter: C')\n",
    "axe[0,1].imshow(X_train[1].reshape(28,28),cmap='gray')\n",
    "axe[0,1].set_title('label: 6  letter: F')\n",
    "axe[1,0].imshow(X_train[2].reshape(28,28),cmap='gray')\n",
    "axe[1,0].set_title('label: 2  letter: B')\n",
    "axe[1,1].imshow(X_train[4].reshape(28,28),cmap='gray')\n",
    "axe[1,1].set_title('label: 13  letter: M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ad1fcd-6414-44df-960e-ac346a893208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (27455, 784)\n",
      "Shape of y_train: (27455, 24)\n",
      "Shape of X_test: (7172, 784)\n",
      "Shape of y_test: (7172, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: \" + str(X_train.shape))\n",
    "print(\"Shape of y_train: \" + str(y_train.shape))\n",
    "print(\"Shape of X_test: \" + str(X_test.shape))\n",
    "print(\"Shape of y_test: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e53fb-0adc-442b-883c-0f523f10abcb",
   "metadata": {},
   "source": [
    "## Task 2: Implement an MLP to classify image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd33fa4-5274-4fa3-a7bf-08363c6660f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for all activation functions\n",
    "class ActivationFunction:\n",
    "    # Static method for the ReLU (Rectified Linear Unit) activation function.\n",
    "    # ReLU is defined as the positive part of its input.\n",
    "    # Input: A numpy array 'x'.\n",
    "    # Output: A numpy array where each element is the max between 0 and the corresponding element in 'x'.\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    # Static method for the derivative of the ReLU function.\n",
    "    # This is used in backpropagation during neural network training.\n",
    "    # Input: A numpy array 'x'.\n",
    "    # Output: A numpy array where each element is 1 if the corresponding element in 'x' is greater than 0, otherwise 0.\n",
    "    @staticmethod\n",
    "    def relu_derivative(x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    # Static method for the softmax function.\n",
    "    # Softmax is often used in the output layer of a neural network for multi-class classification.\n",
    "    # It converts the input array into a probability distribution.\n",
    "    # Input: A 2D numpy array 'x'. Each row represents a set of logits for a single sample.\n",
    "    # Output: A 2D numpy array where each row sums to 1 and represents the probability distribution for the corresponding sample.\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))  # subtract max for numerical stability\n",
    "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "    # Static method for the sigmoid function.\n",
    "    # Sigmoid is often used in the output layer of a binary classification neural network.\n",
    "    # It converts the input into a value between 0 and 1.\n",
    "    # Input: A numpy array 'x'.\n",
    "    # Output: A numpy array where each element is the sigmoid of the corresponding element in 'x'.\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "      clipped_x = np.clip(x, -500, 500)  # clip input to prevent overflow in the exponential function\n",
    "      return 1 / (1 + np.exp(-clipped_x))\n",
    "\n",
    "    # Static method for the Leaky ReLU activation function.\n",
    "    # Leaky ReLU allows a small, non-zero gradient when the input is negative.\n",
    "    # Input: A numpy array 'x' and an optional slope parameter 'alpha' for negative inputs.\n",
    "    # Output: A numpy array where each element is either the corresponding element in 'x' (if positive) or 'alpha' times that element (if negative).\n",
    "    @staticmethod\n",
    "    def leaky_relu(x, alpha=0.01):\n",
    "        return np.where(x > 0, x, alpha * x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bad3a08-5a73-4237-a8f5-1a1e9d467689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definition for a Multi-Layer Perceptron (MLP) neural network.\n",
    "class MLP:\n",
    "\n",
    "    # Constructor for the MLP class.\n",
    "    # Inputs:\n",
    "    # - layer_sizes: A list of integers representing the sizes of each layer in the network.\n",
    "    # - learning_rate: A float representing the learning rate for gradient descent.\n",
    "    def __init__(self, layer_sizes, learning_rate=0.01):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        # Initialize weights with random values scaled by the square root of 2 divided by the size of the previous layer.\n",
    "        self.weights = [np.random.randn(prev_layer, next_layer) * np.sqrt(2. / prev_layer)\n",
    "                        for prev_layer, next_layer in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "        # Initialize biases as zero vectors.\n",
    "        self.biases = [np.zeros((1, next_layer)) for next_layer in layer_sizes[1:]]\n",
    "\n",
    "    # Method for forward propagation.\n",
    "    # Inputs:\n",
    "    # - X: A numpy array representing the input data.\n",
    "    # - activation: A string specifying the activation function to use ('relu', 'sigmoid', or 'leakyrelu').\n",
    "    # Outputs:\n",
    "    # - activations: A list of numpy arrays representing the activations of each layer.\n",
    "    # - zs: A list of numpy arrays representing the weighted sums before activation in each layer.\n",
    "    def forward(self, X, activation='relu'):\n",
    "        self.activations = [X]\n",
    "        self.zs = []\n",
    "\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(self.activations[-1], w) + b\n",
    "            self.zs.append(z)\n",
    "            if activation == 'relu':\n",
    "                activation_output = ActivationFunction.relu(z)\n",
    "            elif activation == 'sigmoid':\n",
    "                activation_output = ActivationFunction.sigmoid(z)\n",
    "            elif activation == 'leakyrelu':\n",
    "                activation_output = ActivationFunction.leaky_relu(z)\n",
    "            else:\n",
    "                raise ValueError(\"Activation function not supported.\")\n",
    "            self.activations.append(activation_output)\n",
    "\n",
    "        # Apply softmax activation to the output layer.\n",
    "        self.activations[-1] = ActivationFunction.softmax(self.zs[-1])\n",
    "        return self.activations, self.zs\n",
    "\n",
    "    # Method for backward propagation.\n",
    "    # Inputs:\n",
    "    # - X: A numpy array representing the input data.\n",
    "    # - y: A numpy array representing the target labels.\n",
    "    # - activations: A list of numpy arrays representing the activations of each layer.\n",
    "    # - zs: A list of numpy arrays representing the weighted sums before activation in each layer.\n",
    "    # Outputs:\n",
    "    # - dW: A list of numpy arrays representing the gradients of the loss with respect to the weights.\n",
    "    # - dB: A list of numpy arrays representing the gradients of the loss with respect to the biases.\n",
    "    def backward(self, X, y, activations, zs):\n",
    "      # Calculate the gradient of the loss with respect to the output layer's activations.\n",
    "      delta = activations[-1] - y\n",
    "      # Compute the gradient of the loss with respect to the last layer's weights.\n",
    "      dW = [np.dot(activations[-2].T, delta)]\n",
    "      # Compute the gradient of the loss with respect to the last layer's biases.\n",
    "      dB = [np.sum(delta, axis=0)]\n",
    "\n",
    "      # Iterate backwards through the layers to propagate the gradients.\n",
    "      for l in range(2, len(self.weights) + 1):\n",
    "          # Get the weighted sum before activation for the current layer.\n",
    "          z = zs[-l]\n",
    "          # Compute the derivative of the ReLU activation function for the current layer.\n",
    "          sp = ActivationFunction.relu_derivative(z)\n",
    "          # Update the delta by propagating it backwards and applying the derivative of the activation function.\n",
    "          delta = np.dot(delta, self.weights[-l+1].T) * sp\n",
    "          # Compute the gradient of the loss with respect to the current layer's weights.\n",
    "          dW.insert(0, np.dot(activations[-l-1].T, delta))\n",
    "          # Compute the gradient of the loss with respect to the current layer's biases.\n",
    "          dB.insert(0, np.sum(delta, axis=0))\n",
    "\n",
    "      return dW, dB\n",
    "\n",
    "    # Method to update the weights and biases based on the gradients.\n",
    "    # Inputs:\n",
    "    # - dW: A list of numpy arrays representing the gradients of the loss with respect to the weights.\n",
    "    # - dB: A list of numpy arrays representing the gradients of the loss with respect to the biases.\n",
    "    def update_params(self, dW, dB):\n",
    "        self.weights = [w - self.learning_rate * dw for w, dw in zip(self.weights, dW)]\n",
    "        self.biases = [b - self.learning_rate * db for b, db in zip(self.biases, dB)]\n",
    "\n",
    "    # Method to compute the loss using the cross-entropy function.\n",
    "    # Inputs:\n",
    "    # - y_true: A numpy array representing the true labels.\n",
    "    # - y_pred: A numpy array representing the predicted probabilities.\n",
    "    # Output: A float representing the loss value.\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "      m = y_true.shape[0]\n",
    "      log_probs = np.log(np.clip(y_pred, a_min=1e-15, a_max=1))\n",
    "      loss = -np.sum(y_true * log_probs) / m\n",
    "      return loss\n",
    "\n",
    "    # Method to predict the class labels for the input data.\n",
    "    # Input: A numpy array representing the input data 'X'.\n",
    "    # Output: A numpy array representing the predicted class labels.\n",
    "    def predict(self, X):\n",
    "        # Perform forward propagation to compute the activations of the network.\n",
    "        activations, _ = self.forward(X)\n",
    "        # Return the indices of the maximum values in the output layer (softmax probabilities),\n",
    "        # which correspond to the predicted class labels.\n",
    "        return np.argmax(activations[-1], axis=1)\n",
    "\n",
    "\n",
    "    # Method to train the MLP model.\n",
    "    # Inputs:\n",
    "    # - X: A numpy array representing the input data.\n",
    "    # - y: A numpy array representing the target labels.\n",
    "    # - epochs: An integer representing the number of iterations to train the model.\n",
    "    def fit(self, X, y, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            # Perform forward propagation to compute the activations and weighted sums.\n",
    "            activations, zs = self.forward(X)\n",
    "            # Compute the loss using the cross-entropy function.\n",
    "            loss = self.compute_loss(y, activations[-1])\n",
    "            # Perform backward propagation to compute the gradients of the loss with respect to weights and biases.\n",
    "            dW, dB = self.backward(X, y, activations, zs)\n",
    "            # Update the weights and biases using the gradients.\n",
    "            self.update_params(dW, dB)\n",
    "\n",
    "            # Print the loss every 10 epochs.\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    # Method to evaluate the accuracy of the MLP model.\n",
    "    # Inputs:\n",
    "    # - X: A numpy array representing the input data.\n",
    "    # - y: A numpy array representing the true labels.\n",
    "    # Output: A float representing the accuracy of the model.\n",
    "    def evaluate_acc(self, X, y):\n",
    "        # Use the predict method to get the predicted class labels.\n",
    "        predictions = self.predict(X)\n",
    "        # Calculate the accuracy by comparing the predicted labels with the true labels.\n",
    "        accuracy = sum(predictions == y.argmax(axis=1)) / y.shape[0]\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28fdeeca-abce-435c-a4b0-ca6758b1069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encoding : \n",
      "(27455, 24)\n",
      "(7172, 24)\n",
      "After encoding : \n",
      "(658920, 2)\n",
      "(172128, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# one hot encode y\n",
    "encoder = OneHotEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(\"Before encoding : \")\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(\"After encoding : \")\n",
    "print(y_train_encoded.shape)\n",
    "print(y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef658dd-50d2-4e81-abd5-839764180bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (27455, 784)\n",
      "y_train shape: (658920, 2)\n",
      "Epoch 0, Loss: 3.5618\n",
      "Epoch 10, Loss: 25.1409\n",
      "Epoch 20, Loss: 27.9346\n",
      "Epoch 30, Loss: 30.0873\n",
      "Epoch 40, Loss: 30.8284\n",
      "Epoch 50, Loss: 27.5836\n",
      "Epoch 60, Loss: 28.9768\n"
     ]
    }
   ],
   "source": [
    "#set number of classes\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "input_size = 784 # we have 784 pixels (Features)\n",
    "output_classes = 24 # we have 24 labels\n",
    "\n",
    "mlp_model = MLP(layer_sizes=[input_size, 128, 64, output_classes], learning_rate=0.01) #setting learning rate to 0.01 to begin\n",
    "\n",
    "#Printing shapes for debugging purposes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train_encoded.shape)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_encoded = label_binarizer.fit_transform(y_train)\n",
    "y_test_encoded = label_binarizer.transform(y_test)\n",
    "\n",
    "\n",
    "# Training Model ================================\n",
    "mlp_model.fit(X_train, y_train_encoded, epochs=100)\n",
    "\n",
    "# Evaluate the Model ================================\n",
    "train_accuracy = mlp_model.evaluate_acc(X_train, y_train_encoded)\n",
    "test_accuracy = mlp_model.evaluate_acc(X_test, y_test_encoded)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd67fb-4c14-4e6e-b476-17ef2d9f9dd4",
   "metadata": {},
   "source": [
    "## Task 3: Running experiments\n",
    "### Experiment 1: Three Different MLP Models\n",
    "Three different models: (1) an MLP with no hidden layer, (2) an MLP with a single hidden layer having ReLU activations, (3) an MLP with 2 hidden layers having ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f8047-f305-415a-bd4f-d64e1f402f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_mlps = [\n",
    "    ([784, 24], 'No Hidden Layer'),\n",
    "    ([784, 64, 24], 'Single Hidden Layer'),\n",
    "    ([784, 128, 128, 24], 'Two Hidden Layers')\n",
    "]\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for model, name in three_mlps:\n",
    "    mlp = MLP(model, learning_rate = 0.001)\n",
    "    #train the model\n",
    "    mlp.fit(X_train, y_train_encoded, epochs=10)\n",
    "\n",
    "    #evaluate on training set\n",
    "    train_accuracy = mlp.evaluate_acc(X_train, y_train_encoded)\n",
    "\n",
    "    #evaluate on test set\n",
    "    test_accuracy = mlp.evaluate_acc(X_test, y_test_encoded)\n",
    "\n",
    "    accuracies.append((name, train_accuracy, test_accuracy))\n",
    "\n",
    "#print accuracies for each model\n",
    "for name, train_accuracy, test_accuracy in accuracies:\n",
    "    print(f\"Model: {name}, Train Accuracy: {train_accuracy*100:.2f}%, Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebe347-5f49-4490-a0bd-d0634d4212d6",
   "metadata": {},
   "source": [
    "Update the MLP class accordingly & then apply L2 regularization to the MLP with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740755f-5ae3-4ac3-9244-ab80b7c47390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, layer_sizes, learning_rate=0.01, reg_lambda=0.01): # add reg_lambda parameter for L2 regularization\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg_lambda = reg_lambda # store regularization parameter\n",
    "        self.weights = [np.random.randn(prev_layer, next_layer) * np.sqrt(2. / prev_layer)\n",
    "                        for prev_layer, next_layer in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "        self.biases = [np.zeros((1, next_layer)) for next_layer in layer_sizes[1:]]\n",
    "\n",
    "    def forward(self, X, activation='relu'):\n",
    "        self.activations = [X]\n",
    "        self.zs = []\n",
    "\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(self.activations[-1], w) + b\n",
    "            self.zs.append(z)\n",
    "            if activation == 'relu':\n",
    "                activation_output = ActivationFunction.relu(z)\n",
    "            elif activation == 'sigmoid':\n",
    "                activation_output = ActivationFunction.sigmoid(z)\n",
    "            elif activation == 'leakyrelu':\n",
    "                activation_output = ActivationFunction.leaky_relu(z)\n",
    "            else:\n",
    "                raise ValueError(\"Activation function not supported.\")\n",
    "            self.activations.append(activation_output)\n",
    "\n",
    "        self.activations[-1] = ActivationFunction.softmax(self.zs[-1])\n",
    "        return self.activations, self.zs\n",
    "\n",
    "    def backward(self, X, y, activations, zs):\n",
    "        delta = activations[-1] - y\n",
    "        dW = [np.dot(activations[-2].T, delta)]\n",
    "        dB = [np.sum(delta, axis=0)]\n",
    "\n",
    "        for l in range(2, len(self.weights) + 1):\n",
    "            z = zs[-l]\n",
    "            sp = ActivationFunction.relu_derivative(z)\n",
    "            delta = np.dot(delta, self.weights[-l+1].T) * sp\n",
    "            dW.insert(0, np.dot(activations[-l-1].T, delta) + self.reg_lambda * self.weights[-l])  # Add L2 regularization term\n",
    "            dB.insert(0, np.sum(delta, axis=0))\n",
    "\n",
    "        return dW, dB\n",
    "\n",
    "    def update_params(self, dW, dB):\n",
    "        self.weights = [w - self.learning_rate * dw for w, dw in zip(self.weights, dW)]\n",
    "        self.biases = [b - self.learning_rate * db for b, db in zip(self.biases, dB)]\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        log_probs = np.log(np.clip(y_pred, a_min=1e-15, a_max=1))\n",
    "        loss = -np.sum(y_true * log_probs) / m\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations, _ = self.forward(X)\n",
    "        return np.argmax(activations[-1], axis=1)\n",
    "\n",
    "    def fit(self, X, y, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            activations, zs = self.forward(X)\n",
    "            loss = self.compute_loss(y, activations[-1])\n",
    "            dW, dB = self.backward(X, y, activations, zs)\n",
    "            self.update_params(dW, dB)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def evaluate_acc(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = sum(predictions == y.argmax(axis=1)) / y.shape[0]\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ec22d-45bb-405f-a32b-841bd855cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model architecture and create the new MLP object\n",
    "mlp_regularized = MLP(layer_sizes=[784, 128, 128, 24], learning_rate=0.01, reg_lambda=0.0001)\n",
    "\n",
    "#train the MLP with L2 regularization\n",
    "mlp_regularized.fit(X_train, y_train_encoded, epochs=300)\n",
    "\n",
    "#evaluate the performance of the trained model on the test data\n",
    "accuracy_L2reg = mlp_regularized.evaluate_acc(X_test, y_test_encoded)\n",
    "print(\"Test Accuracy - Regularized Model with L2 regularization: {:.2f}%\".format(accuracy_L2reg * 100))\n",
    "\n",
    "#evaluate training accuracy\n",
    "accuracy_L2reg_train = mlp_regularized.evaluate_acc(X_train, y_train_encoded)\n",
    "print(\"Train Accuracy - Regularized Model with L2 regularization: {:.2f}%\".format(accuracy_L2reg_train * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13936ae2-afe4-42bd-98c0-cbfa6afff4b1",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083d172-ec85-4da4-aefa-aea735c48bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing and reshaping features\n",
    "X_train = train_df.drop('label', axis=1).values.reshape(-1, 28, 28, 1) / 255.0\n",
    "X_test = test_df.drop('label', axis=1).values.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# one-hot encoding labels\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(train_df['label'])\n",
    "y_test = label_binarizer.transform(test_df['label'])\n",
    "\n",
    "# defining image data generator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=0,\n",
    "    height_shift_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# defining the ConvNet architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(24, activation='softmax')\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
